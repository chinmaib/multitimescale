
@inproceedings{masci_stacked_2011,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Stacked {Convolutional} {Auto}-{Encoders} for {Hierarchical} {Feature} {Extraction}},
	isbn = {978-3-642-21735-7},
	doi = {10.1007/978-3-642-21735-7_7},
	abstract = {We present a novel convolutional auto-encoder (CAE) for unsupervised feature learning. A stack of CAEs forms a convolutional neural network (CNN). Each CAE is trained using conventional on-line gradient descent without additional regularization terms. A max-pooling layer is essential to learn biologically plausible features consistent with those found by previous approaches. Initializing a CNN with filters of a trained CAE stack yields superior performance on a digit (MNIST) and an object recognition (CIFAR10) benchmark.},
	language = {en},
	booktitle = {Artificial {Neural} {Networks} and {Machine} {Learning} – {ICANN} 2011},
	publisher = {Springer},
	author = {Masci, Jonathan and Meier, Ueli and Cireşan, Dan and Schmidhuber, Jürgen},
	editor = {Honkela, Timo and Duch, Włodzisław and Girolami, Mark and Kaski, Samuel},
	year = {2011},
	keywords = {classification, convolutional neural network, auto-encoder, unsupervised learning},
	pages = {52--59},
	file = {Springer Full Text PDF:/home/chinmai/Zotero/storage/EGDCWR6U/Masci et al. - 2011 - Stacked Convolutional Auto-Encoders for Hierarchic.pdf:application/pdf},
}

@article{huang_asist_2021,
	title = {{ASIST} {Study} 2 {June} 2021 {Exercises} for {Artificial} {Social} {Intelligence} in {Minecraft} {Search} and {Rescue} for {Teams}},
	url = {https://osf.io/gxpq5},
	doi = {10.17605/OSF.IO/GXPQ5},
	abstract = {Participants will participate in a 1-hour session to install required software appropriately and fill out independent surveys. Then, teams of three qualified participants will participate in a 2.5-hour session to complete an experiment in which they search for victims and rescue them in a Minecraft task environment. Participants will receive training that introduces the rules of the game and provides some hands-on experience with the environment. In the search and rescue task environment, the three participants on each team may choose one of three roles -- Medical Specialist (medic), Search Specialist (searcher), or Heavy Equipment Specialist (engineer) -- and change those roles during the mission.},
	language = {en-us},
	urldate = {2021-06-25},
	author = {Huang, Lixiao and Freeman, Jared and Cooke, Nancy and Dubrow, Samantha and Colonna-Romano, John and Wood, Matt and Buchanan, Verica and Caufman, Stephen},
	month = jun,
	year = {2021},
	note = {Publisher: OSF},
	file = {Snapshot:/home/chinmai/Zotero/storage/S5PNTKKZ/gxpq5.html:text/html},
}

@article{blitch_artificial_1996,
	series = {Army {Applications} of {Artificial} {Intelligence}},
	title = {Artificial intelligence technologies for robot assisted urban search and rescue},
	volume = {11},
	issn = {0957-4174},
	url = {https://www.sciencedirect.com/science/article/pii/0957417496000383},
	doi = {10.1016/0957-4174(96)00038-3},
	abstract = {Structural collapse disasters routinely inspire sympathy not only for victims and their families, but also for heroic rescue personnel who are faced with a tremendously complex, hazardous and often frustrating task environment. Military operations and rescue activities in the aftermath of recent earthquakes and bombings indicate a tremendous need for greater access to denied areas within any crisis site involving collapsed structures. Recent developments in the remote inspection industry show great potential for employment of small robotic micro-rover systems in expanded roles for Urban Search and Rescue. This paper discusses key issues in the application of robotic systems to Urban Search and Rescue (USAR) activities and discusses ongoing development of a knowledge-based system for efficient management of automated search assets. USAR modeling and “micro-bot” employment advantages are addressed first, followed by a discussion of numerical method shortcomings in the context of search asset allocation. KNOBSAR is then proposed as an initial expert system prototype designed to interact with various structural collapse simulation packages and provide advice on search asset allocation to specific entry points within a crisis site. KNOBSAR structure and design is then illustrated in terms of micro-bot allocation scenarios to various collapsed structure entry points. The conclusion drawn from literature review, experimentation and personal experience is that AI technologies in the form of robotic platforms and decision support tools can have a tremendous impact on overall search efficiency for the USAR community, and represent an important field of study for related military applications.},
	language = {en},
	number = {2},
	urldate = {2021-06-25},
	journal = {Expert Systems with Applications},
	author = {Blitch, John G.},
	month = jan,
	year = {1996},
	pages = {109--124},
	file = {ScienceDirect Snapshot:/home/chinmai/Zotero/storage/BBGA5LRT/0957417496000383.html:text/html;ScienceDirect Full Text PDF:/home/chinmai/Zotero/storage/ETQQPZC5/Blitch - 1996 - Artificial intelligence technologies for robot ass.pdf:application/pdf},
}

@inproceedings{merino_cooperative_2005,
	title = {Cooperative {Fire} {Detection} using {Unmanned} {Aerial} {Vehicles}},
	doi = {10.1109/ROBOT.2005.1570388},
	abstract = {The paper presents a framework for cooperative fire detection by means of a fleet of heterogeneous UAVs. Computer vision techniques are used to detect and localize fires from infrared and visual images and other data provided by the cameras and other sensors on-board the UAVs. The paper deals with the techniques used to decrease the uncertainty in fire detection and increase the accuracy in fire localisation by means of the cooperation of the information provided by several UAVs. The presented methods have been developed in the COMETS multi-UAV project.},
	booktitle = {Proceedings of the 2005 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Merino, L. and Caballero, F. and Martinez-de Dios, J.R. and Ollero, A.},
	month = apr,
	year = {2005},
	note = {ISSN: 1050-4729},
	keywords = {aerial robotic vehicles, Cameras, Cooperative perception, data fusion, Fires, Helicopters, Infrared detectors, infrared images, Infrared imaging, Infrared sensors, Monitoring, Robots, Unmanned aerial vehicles, Vehicle detection},
	pages = {1884--1889},
	file = {IEEE Xplore Abstract Record:/home/chinmai/Zotero/storage/SKI2YCGP/1570388.html:text/html},
}

@article{madni_architectural_2018,
	title = {Architectural {Framework} for {Exploring} {Adaptive} {Human}-{Machine} {Teaming} {Options} in {Simulated} {Dynamic} {Environments}},
	volume = {6},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2079-8954/6/4/44},
	doi = {10.3390/systems6040044},
	abstract = {With the growing complexity of environments in which systems are expected to operate, adaptive human-machine teaming (HMT) has emerged as a key area of research. While human teams have been extensively studied in the psychological and training literature, and agent teams have been investigated in the artificial intelligence research community, the commitment to research in HMT is relatively new and fueled by several technological advances such as electrophysiological sensors, cognitive modeling, machine learning, and adaptive/adaptable human-machine systems. This paper presents an architectural framework for investigating HMT options in various simulated operational contexts including responding to systemic failures and external disruptions. The paper specifically discusses new and novel roles for machines made possible by new technology and offers key insights into adaptive human-machine teams. Landed aircraft perimeter security is used as an illustrative example of an adaptive cyber-physical-human system (CPHS). This example is used to illuminate the use of the HMT framework in identifying the different human and machine roles involved in this scenario. The framework is domain-independent and can be applied to both defense and civilian adaptive HMT. The paper concludes with recommendations for advancing the state-of-the-art in HMT.},
	language = {en},
	number = {4},
	urldate = {2021-06-25},
	journal = {Systems},
	author = {Madni, Azad M. and Madni, Carla C.},
	month = dec,
	year = {2018},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {machine learning, architectural framework, dynamic function allocation, human-machine teaming, human-machine teams, intent inferencing},
	pages = {44},
	file = {Snapshot:/home/chinmai/Zotero/storage/3TLAV6Z5/44.html:text/html;Full Text PDF:/home/chinmai/Zotero/storage/TQ6V4YS9/Madni and Madni - 2018 - Architectural Framework for Exploring Adaptive Hum.pdf:application/pdf},
}

@inproceedings{urlings_teaming_2002,
	address = {Heidelberg},
	series = {Advances in {Soft} {Computing}},
	title = {Teaming {Human} and {Machine}: {A} {Conceptual} {Framework}},
	isbn = {978-3-7908-1782-9},
	shorttitle = {Teaming {Human} and {Machine}},
	doi = {10.1007/978-3-7908-1782-9_51},
	abstract = {Advances in automation and especially artificial intelligence have enabled the formation of rather unique teams with human and (electronic) machine members. This paper proposes a conceptual framework for teaming human and machine. The basis of this framework will be the introduction of the machine into the traditional situation where the human is solely responsible for managing, control and execution of all activities. Focus will be on the identification and classification of activities to be allocated to the machine. Task management and coordination between human and machine will be identified as a specific area of research and design concern.},
	language = {en},
	booktitle = {Hybrid {Information} {Systems}},
	publisher = {Physica-Verlag HD},
	author = {Urlings, Pierre and Jain, Lakhmi C.},
	editor = {Abraham, Ajith and Köppen, Mario},
	year = {2002},
	keywords = {Blackboard System, Cial Neural Network, Crew Resource Management, Information Processing Technique, Operator Assistant},
	pages = {711--721},
	file = {Springer Full Text PDF:/home/chinmai/Zotero/storage/XIKWUWGB/Urlings and Jain - 2002 - Teaming Human and Machine A Conceptual Framework.pdf:application/pdf},
}

@book{johnson_malmo_nodate,
	title = {The {Malmo} {Platform} for {Artificial} {Intelligence} {Experimentation} *},
	abstract = {Abstract We present Project Malmo -an AI experimentation platform built on top of the popular computer game Minecraft, and designed to support fundamental research in artificial intelligence. As the AI research community pushes for artificial general intelligence (AGI), experimentation platforms are needed that support the development of flexible agents that learn to solve diverse tasks in complex environments. Minecraft is an ideal foundation for such a platform, as it exposes agents to complex 3D worlds, coupled with infinitely varied game-play. Project Malmo provides a sophisticated abstraction layer on top of Minecraft that supports a wide range of experimentation scenarios, ranging from navigation and survival to collaboration and problem solving tasks. In this demo we present the Malmo platform and its capabilities. The platform is publicly released as open source software at IJCAI, to support openness and collaboration in AI research.},
	author = {Johnson, Matthew and Hofmann, Katja and Hutton, Tim and Microsoft, David Bignell},
	file = {Citeseer - Full Text PDF:/home/chinmai/Zotero/storage/N66SV2VH/Johnson et al. - The Malmo Platform for Artificial Intelligence Exp.pdf:application/pdf;Citeseer - Snapshot:/home/chinmai/Zotero/storage/SXG2JNNK/download.html:text/html},
}

@misc{noauthor_pii_nodate,
	title = {{PII}: 0957-4174(96)00038-3 {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {{PII}},
	url = {https://reader.elsevier.com/reader/sd/pii/0957417496000383?token=18FB455091088F4C2983DB4BD84DE44FE490DC71648F950A3A518617681E4AD6BA2922C5F931373888A7CE477EA6BF8B&originRegion=us-east-1&originCreation=20210623195649},
	language = {en},
	urldate = {2021-06-23},
	doi = {10.1016/0957-4174(96)00038-3},
	note = {ISSN: 0957-4174},
	file = {Snapshot:/home/chinmai/Zotero/storage/K9R9LFXL/0957417496000383.html:text/html},
}

@article{roberts_unmanned_nodate,
	title = {Unmanned {Vehicle} {Collaboration} {Research} {Environment} for {Maritime} {Search} and {Rescue}},
	abstract = {With the proliferation of unmanned air vehicles in the last few decades, there has been a series of applications proposed around the concept of collaborative unmanned systems. However, it is difficult to assess at what point collaboration actually results in true benefits to mission performance and also difficult to determine the degree of benefit possible to achieve. This paper describes a framework which allows decision makers to analyze the effectiveness of a coordinated group of UAVs as a function of the physical mission parameters, showing benefit over a single UAV or uncoordinated multiaircraft approach. To demonstrate the use of the framework, a case study is presented for a maritime search and rescue mission on a parameterized mission space. From the analysis, critical points in the mission space were found where the coordinated group of UAVs brought no additional benefits to the mission. However, at other points they were able to cut down the mission time by more than one hour. This framework can be used to guide decision makers and help estimate the effectiveness of coordinated UAVs in a parameterized mission space.},
	language = {en},
	author = {Roberts, William and Griendling, Kelly and Gray, Anthony and Mavris, Dimitri N},
	pages = {14},
	file = {Roberts et al. - Unmanned Vehicle Collaboration Research Environmen.pdf:/home/chinmai/Zotero/storage/PSTVI2K8/Roberts et al. - Unmanned Vehicle Collaboration Research Environmen.pdf:application/pdf},
}

@inproceedings{mehmood_multi_2018,
	title = {Multi {Criteria} {Decision} {Analysis} ({MCDA}) of {Unmanned} {Aerial} {Vehicles} ({UAVs}) as a {Part} of {Standard} {Response} to {Emergencies}},
	url = {https://portal.findresearcher.sdu.dk/en/publications/multi-criteria-decision-analysis-mcda-of-unmanned-aerial-vehicles},
	language = {English},
	urldate = {2021-06-23},
	booktitle = {Proceeding of the {International} {Conference} on {Green} {Computing} and {Engineering} {Technologies} 2018},
	publisher = {Gyancity International Publishers},
	author = {Mehmood, Saqib and Ahmed, Shakeel and Kristensen, Anders Schmidt and Ahsan, Dewan},
	month = may,
	year = {2018},
	file = {Snapshot:/home/chinmai/Zotero/storage/TGJ932HZ/multi-criteria-decision-analysis-mcda-of-unmanned-aerial-vehicles.html:text/html},
}

@inproceedings{liu_multi-timescale_2015,
	address = {Lisbon, Portugal},
	title = {Multi-{Timescale} {Long} {Short}-{Term} {Memory} {Neural} {Network} for {Modelling} {Sentences} and {Documents}},
	url = {https://www.aclweb.org/anthology/D15-1280},
	doi = {10.18653/v1/D15-1280},
	urldate = {2021-06-23},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Pengfei and Qiu, Xipeng and Chen, Xinchi and Wu, Shiyu and Huang, Xuanjing},
	month = sep,
	year = {2015},
	pages = {2326--2335},
	file = {Full Text PDF:/home/chinmai/Zotero/storage/H7DAWVF7/Liu et al. - 2015 - Multi-Timescale Long Short-Term Memory Neural Netw.pdf:application/pdf},
}

@inproceedings{kitano_robocup_1999,
	title = {{RoboCup} {Rescue}: search and rescue in large-scale disasters as a domain for autonomous agents research},
	volume = {6},
	shorttitle = {{RoboCup} {Rescue}},
	doi = {10.1109/ICSMC.1999.816643},
	abstract = {Disaster rescue is one of the most serious social issue which involves very large numbers of heterogeneous agents in the hostile environment. RoboCup-Rescue intends to promote research and development in this socially significant domain by creating a standard simulator and forum for researchers and practitioners. While the rescue domain intuitively appealing as large scale multi-agent domains, it has not yet given through analysis on its domain characteristics. In this paper, we present detailed analysis on the task domain and elucidate characteristics necessary for multi-agent systems for this domain.},
	booktitle = {{IEEE} {SMC}'99 {Conference} {Proceedings}. 1999 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({Cat}. {No}.{99CH37028})},
	author = {Kitano, H. and Tadokoro, S. and Noda, I. and Matsubara, H. and Takahashi, T. and Shinjou, A. and Shimada, S.},
	month = oct,
	year = {1999},
	note = {ISSN: 1062-922X},
	keywords = {Artificial intelligence, Autonomous agents, Cities and towns, Collaboration, Earthquakes, Large-scale systems, Modeling, Multiagent systems, Real time systems, Robot kinematics},
	pages = {739--743 vol.6},
	file = {IEEE Xplore Abstract Record:/home/chinmai/Zotero/storage/M62KSB9G/816643.html:text/html;IEEE Xplore Full Text PDF:/home/chinmai/Zotero/storage/8NBURGR5/Kitano et al. - 1999 - RoboCup Rescue search and rescue in large-scale d.pdf:application/pdf},
}

@article{madni_architectural_2018-1,
	title = {Architectural {Framework} for {Exploring} {Adaptive} {Human}-{Machine} {Teaming} {Options} in {Simulated} {Dynamic} {Environments}},
	volume = {6},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2079-8954/6/4/44},
	doi = {10.3390/systems6040044},
	abstract = {With the growing complexity of environments in which systems are expected to operate, adaptive human-machine teaming (HMT) has emerged as a key area of research. While human teams have been extensively studied in the psychological and training literature, and agent teams have been investigated in the artificial intelligence research community, the commitment to research in HMT is relatively new and fueled by several technological advances such as electrophysiological sensors, cognitive modeling, machine learning, and adaptive/adaptable human-machine systems. This paper presents an architectural framework for investigating HMT options in various simulated operational contexts including responding to systemic failures and external disruptions. The paper specifically discusses new and novel roles for machines made possible by new technology and offers key insights into adaptive human-machine teams. Landed aircraft perimeter security is used as an illustrative example of an adaptive cyber-physical-human system (CPHS). This example is used to illuminate the use of the HMT framework in identifying the different human and machine roles involved in this scenario. The framework is domain-independent and can be applied to both defense and civilian adaptive HMT. The paper concludes with recommendations for advancing the state-of-the-art in HMT.},
	language = {en},
	number = {4},
	urldate = {2021-06-23},
	journal = {Systems},
	author = {Madni, Azad M. and Madni, Carla C.},
	month = dec,
	year = {2018},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {machine learning, architectural framework, dynamic function allocation, human-machine teaming, human-machine teams, intent inferencing},
	pages = {44},
	file = {Snapshot:/home/chinmai/Zotero/storage/9ZZG3HRE/htm.html:text/html;Full Text PDF:/home/chinmai/Zotero/storage/L8PWCFN7/Madni and Madni - 2018 - Architectural Framework for Exploring Adaptive Hum.pdf:application/pdf},
}

@inproceedings{takeda_multi-timescale_2018,
	title = {Multi-timescale {Feature}-extraction {Architecture} of {Deep} {Neural} {Networks} for {Acoustic} {Model} {Training} from {Raw} {Speech} {Signal}},
	doi = {10.1109/IROS.2018.8593925},
	abstract = {This paper describes a new architecture of deep neural networks (DNNs) for acoustic models. Training DNNs from raw speech signals will provide 1) novel features of signals, 2) normalization-free processing such as utterance-wise mean subtraction, and 3) low-latency speech recognition for robot audition. Exploiting the longer context of raw speech signals seems useful in improving recognition accuracy. However, naive use of longer contexts results in the loss of short-term patterns; thus, recognition accuracy degrades. We propose a multi-timescale feature-extraction architecture of DNNs with blocks of different time scales, which enable capturing long- and short-term patterns of speech signals. Each block consists of complex-valued networks that correspond to Fourier and filterbank transformations for analysis. Experiments showed that the proposed multi-timescale architecture reduced the word error rate by about 3\% compared with those only with the longterm context. Analysis of the extracted features revealed that our architecture efficiently captured the slow and fast changes of speech features.},
	booktitle = {2018 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Takeda, Ryu and Nakadai, Kazuhiro and Komatani, Kazunori},
	month = oct,
	year = {2018},
	note = {ISSN: 2153-0866},
	keywords = {Feature extraction, Training, Robots, Acoustics, Artificial neural networks, Filter banks, Splicing},
	pages = {2503--2510},
	file = {IEEE Xplore Abstract Record:/home/chinmai/Zotero/storage/ZRUXZTXG/8593925.html:text/html;IEEE Xplore Full Text PDF:/home/chinmai/Zotero/storage/JX33NQ7E/Takeda et al. - 2018 - Multi-timescale Feature-extraction Architecture of.pdf:application/pdf},
}

@article{massoz_multi-timescale_2018,
	title = {Multi-{Timescale} {Drowsiness} {Characterization} {Based} on a {Video} of a {Driver}’s {Face}},
	volume = {18},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/18/9/2801},
	doi = {10.3390/s18092801},
	abstract = {Drowsiness is a major cause of fatal accidents, in particular in transportation. It is therefore crucial to develop automatic, real-time drowsiness characterization systems designed to issue accurate and timely warnings of drowsiness to the driver. In practice, the least intrusive, physiology-based approach is to remotely monitor, via cameras, facial expressions indicative of drowsiness such as slow and long eye closures. Since the system\&rsquo;s decisions are based upon facial expressions in a given time window, there exists a trade-off between accuracy (best achieved with long windows, i.e., at long timescales) and responsiveness (best achieved with short windows, i.e., at short timescales). To deal with this trade-off, we develop a multi-timescale drowsiness characterization system composed of four binary drowsiness classifiers operating at four distinct timescales (5 s, 15 s, 30 s, and 60 s) and trained jointly. We introduce a multi-timescale ground truth of drowsiness, based on the reaction times (RTs) performed during standard Psychomotor Vigilance Tasks (PVTs), that strategically enables our system to characterize drowsiness with diverse trade-offs between accuracy and responsiveness. We evaluated our system on 29 subjects via leave-one-subject-out cross-validation and obtained strong results, i.e., global accuracies of 70\%, 85\%, 89\%, and 94\% for the four classifiers operating at increasing timescales, respectively.},
	language = {en},
	number = {9},
	urldate = {2021-06-23},
	journal = {Sensors},
	author = {Massoz, Quentin and Verly, Jacques G. and Van Droogenbroeck, Marc},
	month = sep,
	year = {2018},
	note = {Number: 9
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {convolutional neural network, driver monitoring, drowsiness, eye closure dynamics, multi-timescale, psychomotor vigilance task, reaction time},
	pages = {2801},
	file = {Snapshot:/home/chinmai/Zotero/storage/85EIZXIV/htm.html:text/html;Full Text PDF:/home/chinmai/Zotero/storage/3Y522SV5/Massoz et al. - 2018 - Multi-Timescale Drowsiness Characterization Based .pdf:application/pdf},
}

@article{kobayashi_made--order_2009,
	title = {Made-to-order spiking neuron model equipped with a multi-timescale adaptive threshold},
	volume = {3},
	issn = {1662-5188},
	url = {https://www.frontiersin.org/articles/10.3389/neuro.10.009.2009/full},
	doi = {10.3389/neuro.10.009.2009},
	abstract = {Information is transmitted in the brain through various kinds of neurons that respond differently to the same signal. Full characteristics including cognitive functions of the brain should ultimately be comprehended by building simulators capable of precisely mirroring spike responses of a variety of neurons. Neuronal modeling that had remained on a qualitative level has recently advanced to a quantitative level, but is still incapable of accurately predicting biological data and requires high computational cost. In this study, we devised a simple, fast computational model that can be tailored to any cortical neuron not only for reproducing but also for predicting a variety of spike responses to greatly fluctuating currents. The key features of this model are a multi-time scale adaptive threshold predictor and a nonresetting leaky integrator. This model is capable of reproducing a rich variety of neuronal spike responses, including regular spiking, intrinsic bursting, fast spiking, and chattering, by adjusting only three adaptive threshold parameters. This model can express a continuous variety of the firing characteristics in a three-dimensional parameter space rather than just those identified in the conventional discrete categorization. Both high flexibility and low computational cost would help to model the real brain function faithfully and examine how network properties may be influenced by the distributed characteristics of component neurons. Ryota Kobayashi and Yasuhiro Tsubo contributed equally to this work.},
	language = {English},
	urldate = {2021-06-23},
	journal = {Frontiers in Computational Neuroscience},
	author = {Kobayashi, Ryota and Tsubo, Yasuhiro and Shinomoto, Shigeru},
	year = {2009},
	note = {Publisher: Frontiers},
	keywords = {adaptive threshold, brain simulator, cortical neuron, fluctuating input, leaky integrate-and-fire model, parameter optimization, predicting spike times},
	file = {Full Text PDF:/home/chinmai/Zotero/storage/6R5FKFTN/Kobayashi et al. - 2009 - Made-to-order spiking neuron model equipped with a.pdf:application/pdf},
}

@article{modayil_multi-timescale_2014,
	title = {Multi-timescale nexting in a reinforcement learning robot},
	volume = {22},
	issn = {1059-7123},
	url = {https://doi.org/10.1177/1059712313511648},
	doi = {10.1177/1059712313511648},
	abstract = {The term ‘nexting’ has been used by psychologists to refer to the propensity of people and many other animals to continually predict what will happen next in an immediate, local, and personal sense. The ability to ‘next’ constitutes a basic kind of awareness and knowledge of one’s environment. In this paper we present results with a robot that learns to next in real time, making thousands of predictions about sensory input signals at timescales from 0.1 to 8 seconds. Our predictions are formulated as a generalization of the value functions commonly used in reinforcement learning, where now an arbitrary function of the sensory input signals is used as a pseudo reward, and the discount rate determines the timescale. We show that six thousand predictions, each computed as a function of six thousand features of the state, can be learned and updated online ten times per second on a laptop computer, using the standard temporal-difference(λ) algorithm with linear function approximation. This approach is sufficiently computationally efficient to be used for real-time learning on the robot and sufficiently data efficient to achieve substantial accuracy within 30 minutes. Moreover, a single tile-coded feature representation suffices to accurately predict many different signals over a significant range of timescales. We also extend nexting beyond simple timescales by letting the discount rate be a function of the state and show that nexting predictions of this more general form can also be learned with substantial accuracy. General nexting provides a simple yet powerful mechanism for a robot to acquire predictive knowledge of the dynamics of its environment.},
	language = {en},
	number = {2},
	urldate = {2021-06-23},
	journal = {Adaptive Behavior},
	author = {Modayil, Joseph and White, Adam and Sutton, Richard S},
	month = apr,
	year = {2014},
	note = {Publisher: SAGE Publications Ltd STM},
	keywords = {predictive knowledge, Reinforcement learning, robotics, temporal difference learning},
	pages = {146--160},
	file = {SAGE PDF Full Text:/home/chinmai/Zotero/storage/KE7IFVIF/Modayil et al. - 2014 - Multi-timescale nexting in a reinforcement learnin.pdf:application/pdf},
}

@article{shin_multi-timescale_2019,
	title = {Multi-timescale, multi-period decision-making model development by combining reinforcement learning and mathematical programming},
	volume = {121},
	issn = {0098-1354},
	url = {https://www.sciencedirect.com/science/article/pii/S0098135418308913},
	doi = {10.1016/j.compchemeng.2018.11.020},
	abstract = {This study focuses on the linkage between decision layers that have different time scales. The resulting expansion of the boundary of decision-making process can provide more robust and flexible management and operation strategies by resolving inconsistencies between different levels. For this, we develop a multi-timescale decision-making model that combines Markov decision process (MDP) and mathematical programming (MP) in a complementary way and introduce a computationally tractable solution algorithm based on reinforcement learning (RL) to solve the MP-embedded MDP problem. To support the integration of the decision hierarchy, a data-driven uncertainty prediction model is suggested which is valid across all time scales considered. A practical example of refinery procurement and production planning is presented to illustrate the proposed method, along with numerical results of a benchmark case study.},
	language = {en},
	urldate = {2021-06-23},
	journal = {Computers \& Chemical Engineering},
	author = {Shin, Joohyun and Lee, Jay H.},
	month = feb,
	year = {2019},
	keywords = {Reinforcement learning, Decision under uncertainty, Markov decision process, Mathematical programming, Multi-timescale decision making},
	pages = {556--573},
	file = {ScienceDirect Snapshot:/home/chinmai/Zotero/storage/GWPFWSJS/S0098135418308913.html:text/html;ScienceDirect Full Text PDF:/home/chinmai/Zotero/storage/6SW687E9/Shin and Lee - 2019 - Multi-timescale, multi-period decision-making mode.pdf:application/pdf},
}

@incollection{edelkamp_chapter_2012,
	address = {San Francisco},
	title = {Chapter 1 - {Introduction}},
	isbn = {978-0-12-372512-7},
	url = {https://www.sciencedirect.com/science/article/pii/B9780123725127000018},
	abstract = {Algorithms are specifications of action sequences, similar to recipes for cooking. The description should be concrete enough to cook a tasteful meal. On the other hand, some abstraction is necessary to keep the presentation readable; no one teaches the cook how to dice onions. In presenting algorithms in computer science, the situation is similar. The presentation should be concrete enough to allow analysis and reimplementation, but abstract enough to be ported on different programming languages and machines. The process of problem solving can often be modeled as a search in a state space starting from some given initial state with rules describing how to transform one state into another. They have to be applied over and over again to eventually satisfy some goal condition. In many areas of computer science, heuristics are viewed as practical rules of thumb. In artificial intelligence search, however, heuristics are well-defined mappings of states to numbers. There are different types of search heuristics. This chapter introduces notational background, specific puzzles, and general problem formalisms. It recalls the success story of heuristic search and studies heuristics as efficiently computable lower bounds.},
	language = {en},
	urldate = {2021-06-23},
	booktitle = {Heuristic {Search}},
	publisher = {Morgan Kaufmann},
	author = {Edelkamp, Stefan and Schrödl, Stefan},
	editor = {Edelkamp, Stefan and Schrödl, Stefan},
	month = jan,
	year = {2012},
	doi = {10.1016/B978-0-12-372512-7.00001-8},
	keywords = {Markov decision process, admissible heuristic, asymptotic resource consumption, complexity theory, computability theory, consistent heuristic, production system, route planning, Rubik's Cube, sliding-tile problem, Sokoban, STRIPS-type planning, symbolic logic, traveling salesman problem},
	pages = {3--46},
	file = {ScienceDirect Snapshot:/home/chinmai/Zotero/storage/YEY64LQC/B9780123725127000018.html:text/html;ScienceDirect Full Text PDF:/home/chinmai/Zotero/storage/TSMWX39Q/Edelkamp and Schrödl - 2012 - Chapter 1 - Introduction.pdf:application/pdf},
}

@misc{noauthor_markov_nodate,
	title = {Markov {Decision} {Process} - an overview {\textbar} {ScienceDirect} {Topics}},
	url = {https://www.sciencedirect.com/topics/computer-science/markov-decision-process},
	urldate = {2021-06-23},
	file = {Markov Decision Process - an overview | ScienceDirect Topics:/home/chinmai/Zotero/storage/9KIX2C3G/markov-decision-process.html:text/html},
}

@book{chauvin_hierarchical_2018,
	title = {Hierarchical {Decision}-{Making} for {Autonomous} {Driving}},
	abstract = {Index Terms - [Decision-Making], [Scene Understanding], [Uncertainty Handling], [Reinforcement Learning], [Autonomous Driving]. In this informal paper, I want to share my vision on two components that form the brain of Autonomous Vehicles: Scene Understanding and Decision-Making. What are their roles in a modular architecture? What are some of the difficulties regarding their implementation? How can they be overcome? In addition, I would like to share recent references for further reading among some of my favourite sources of reflexion.},
	author = {Chauvin, Simon},
	month = aug,
	year = {2018},
	doi = {10.13140/RG.2.2.24352.43526},
}

@inproceedings{kratzke_search_2010,
	title = {Search and {Rescue} {Optimal} {Planning} {System}},
	doi = {10.1109/ICIF.2010.5712114},
	abstract = {In 1974 the U.S. Coast Guard put into operation its first computerized search and rescue planning system CASP (Computer-Assisted Search Planning) which used a Bayesian approach implemented by a particle filter to produce probability distributions for the location of the search object. These distributions were used for planning search effort. In 2003, the Coast Guard started development of a new decision support system for managing search efforts called Search and Rescue Optimal Planning System (SAROPS). SAROPS has been operational since January, 2007 and is currently the only search planning tool that the Coast Guard uses for maritime searches. SAROPS represents a major advance in search planning technology. This paper reviews the technology behind the tool.},
	booktitle = {2010 13th {International} {Conference} on {Information} {Fusion}},
	author = {Kratzke, Thomas M and Stone, Lawrence D and Frost, John R},
	month = jul,
	year = {2010},
	keywords = {Bayesian, Bayesian methods, Hazards, Leg, Monte Carlo simulation, optimization, particle filters, Planning, Probability distribution, search, Search problems, Uncertainty},
	pages = {1--8},
	file = {IEEE Xplore Full Text PDF:/home/chinmai/Zotero/storage/69744QF8/Kratzke et al. - 2010 - Search and Rescue Optimal Planning System.pdf:application/pdf},
}

@article{tra_hierarchical_nodate,
	title = {Hierarchical {Decision} {Making} for {Search} and {Rescue} {Teamwork}},
	abstract = {This paper focuses on the development of a novel approach for modeling the behavior of agents in the RoboCup Rescue Agent Simulation Competition. A two layered approach is developed, with a macro-level behavior responsible for the strategic, high level decisions and a micro-level behavior dealing with the local particularities of the competition.},
	language = {en},
	author = {Tra, Mircea and Visser, Arnoud},
	pages = {9},
	file = {Tra and Visser - Hierarchical Decision Making for Search and Rescue.pdf:/home/chinmai/Zotero/storage/PTLLJ76J/Tra and Visser - Hierarchical Decision Making for Search and Rescue.pdf:application/pdf},
}

@techreport{frost_review_2001,
	title = {Review of {Search} {Theory}: {Advances} and {Applications} to {Search} and {Rescue} {Decision} {Support}},
	shorttitle = {Review of {Search} {Theory}},
	url = {https://apps.dtic.mil/sti/citations/ADA397065},
	abstract = {Fundamental limitations inherent in manual search planning methods have severely limited the application of advances in several areas that could improve the efficiency and effectiveness of the U.S. Coast Guards search and rescue mission. These areas include advances in search theory, environmental data products, knowledge of detection profiles for various sensors, and knowledge of leeway behavior. The U.S. Coast Guards computerized search planning aids have not kept up with advances in these areas or with technology in general. This report reviews the history and recent advances of search theory and its application to a variety of search problems. It then reviews the history of the U.S. Coast Guards search planning methods, showing where search theory was initially applied, albeit in a necessarily very limited way, and where later modifications departed from the theoretical basis of the original methodology. Several computerized search planning decision support tools are analyzed and compared, as are the differences between an analytic approach and a simulation approach. The results are summarized in a matrix. The U.S. Coast Guard needs a new search planning decision support tool for search and rescue and other missions. This tool should use the simulation approach due to its power and flexibility as compared to analytic techniques.},
	language = {en},
	urldate = {2021-06-23},
	institution = {SOZA AND COMPANY LTD FAIRFAX VA},
	author = {Frost, J. R. and Stone, L. D.},
	month = sep,
	year = {2001},
	note = {Section: Technical Reports},
	file = {Full Text PDF:/home/chinmai/Zotero/storage/LIH93E5K/Frost and Stone - 2001 - Review of Search Theory Advances and Applications.pdf:application/pdf;Snapshot:/home/chinmai/Zotero/storage/38UKRCAT/ADA397065.html:text/html},
}

@article{berger_innovative_2015,
	title = {An innovative multi-agent search-and-rescue path planning approach},
	volume = {53},
	issn = {0305-0548},
	url = {https://www.sciencedirect.com/science/article/pii/S0305054814001749},
	doi = {10.1016/j.cor.2014.06.016},
	abstract = {Search and rescue path planning is known to be computationally hard, and most techniques developed to solve practical size problems have been unsuccessful to estimate an optimality gap. A mixed-integer linear programming (MIP) formulation is proposed to optimally solve the multi-agent discrete search and rescue (SAR) path planning problem, maximizing cumulative probability of success in detecting a target. It extends a single agent decision model to a multi-agent setting capturing anticipated feedback information resulting from possible observation outcomes during projected path execution while expanding possible agent actions to all possible neighboring move directions, considerably augmenting computational complexity. A network representation is further exploited to alleviate problem modeling, constraint specification, and speed-up computation. The proposed MIP approach uses CPLEX problem-solving technology in promptly providing near-optimal solutions for realistic problems, while offering a robust upper bound derived from Lagrangean integrality constraint relaxation. Modeling extension to a closed-loop environment to incorporate real-time action outcomes over a receding time horizon can even be envisioned given acceptable run-time performance. A generalized parameter-driven objective function is then proposed and discussed to suitably define a variety of user-defined objectives. Computational results reporting the performance of the approach clearly show its value.},
	language = {en},
	urldate = {2021-06-23},
	journal = {Computers \& Operations Research},
	author = {Berger, Jean and Lo, Nassirou},
	month = jan,
	year = {2015},
	keywords = {Linear programming, Multi-agent, Search and rescue, Search path planning},
	pages = {24--31},
	file = {ScienceDirect Snapshot:/home/chinmai/Zotero/storage/GTFAERND/S0305054814001749.html:text/html},
}

@article{queralta_collaborative_2020,
	title = {Collaborative {Multi}-{Robot} {Search} and {Rescue}: {Planning}, {Coordination}, {Perception}, and {Active} {Vision}},
	volume = {8},
	issn = {2169-3536},
	shorttitle = {Collaborative {Multi}-{Robot} {Search} and {Rescue}},
	doi = {10.1109/ACCESS.2020.3030190},
	abstract = {Search and rescue (SAR) operations can take significant advantage from supporting autonomous or teleoperated robots and multi-robot systems. These can aid in mapping and situational assessment, monitoring and surveillance, establishing communication networks, or searching for victims. This paper provides a review of multi-robot systems supporting SAR operations, with system-level considerations and focusing on the algorithmic perspectives for multi-robot coordination and perception. This is, to the best of our knowledge, the first survey paper to cover (i) heterogeneous SAR robots in different environments, (ii) active perception in multi-robot systems, while (iii) giving two complementary points of view from the multi-agent perception and control perspectives. We also discuss the most significant open research questions: shared autonomy, sim-to-real transferability of existing methods, awareness of victims' conditions, coordination and interoperability in heterogeneous multi-robot systems, and active perception. The different topics in the survey are put in the context of the different challenges and constraints that various types of robots (ground, aerial, surface, or underwater) encounter in different SAR environments (maritime, urban, wilderness, or other post-disaster scenarios). The objective of this survey is to serve as an entry point to the various aspects of multi-robot SAR systems to researchers in both the machine learning and control fields by giving a global overview of the main approaches being taken in the SAR robotics area.},
	journal = {IEEE Access},
	author = {Queralta, Jorge Peña and Taipalmaa, Jussi and Can Pullinen, Bilge and Sarker, Victor Kathan and Nguyen Gia, Tuan and Tenhunen, Hannu and Gabbouj, Moncef and Raitoharju, Jenni and Westerlund, Tomi},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Collaboration, Robot kinematics, Planning, active perception, active vision, autonomous robots, deep learning (DL), machine learning (ML), multi-agent perception, Multi-robot systems, multi-robot systems (MRS), Robot sensing systems, Robotics, search and rescue (SAR)},
	pages = {191617--191643},
	file = {IEEE Xplore Abstract Record:/home/chinmai/Zotero/storage/9TUZ3HP6/9220149.html:text/html;IEEE Xplore Full Text PDF:/home/chinmai/Zotero/storage/CKL6D2LE/Queralta et al. - 2020 - Collaborative Multi-Robot Search and Rescue Plann.pdf:application/pdf},
}

@article{janner_offline_2021,
	title = {Offline {Reinforcement} {Learning} as {One} {Big} {Sequence} {Modeling} {Problem}},
	url = {http://arxiv.org/abs/2106.02039},
	abstract = {Reinforcement learning (RL) is typically concerned with estimating stationary policies or single-step models, leveraging the Markov property to factorize problems in time. However, we can also view RL as a generic sequence modeling problem, with the goal being to produce a sequence of actions that leads to a sequence of high rewards. Viewed in this way, it is tempting to consider whether high-capacity sequence prediction models that work well in other domains, such as natural-language processing, can also provide effective solutions to the RL problem. To this end, we explore how RL can be tackled with the tools of sequence modeling, using a Transformer architecture to model distributions over trajectories and repurposing beam search as a planning algorithm. Framing RL as sequence modeling problem simplifies a range of design decisions, allowing us to dispense with many of the components common in offline RL algorithms. We demonstrate the flexibility of this approach across long-horizon dynamics prediction, imitation learning, goal-conditioned RL, and offline RL. Further, we show that this approach can be combined with existing model-free algorithms to yield a state-of-the-art planner in sparse-reward, long-horizon tasks.},
	urldate = {2021-12-07},
	journal = {arXiv:2106.02039 [cs]},
	author = {Janner, Michael and Li, Qiyang and Levine, Sergey},
	month = nov,
	year = {2021},
	note = {arXiv: 2106.02039},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/home/chinmai/Zotero/storage/BEEL7B3P/2106.html:text/html;arXiv Fulltext PDF:/home/chinmai/Zotero/storage/3D6YGAP8/Janner et al. - 2021 - Offline Reinforcement Learning as One Big Sequence.pdf:application/pdf},
}

@article{chen_decision_2021,
	title = {Decision {Transformer}: {Reinforcement} {Learning} via {Sequence} {Modeling}},
	shorttitle = {Decision {Transformer}},
	url = {http://arxiv.org/abs/2106.01345},
	abstract = {We introduce a framework that abstracts Reinforcement Learning (RL) as a sequence modeling problem. This allows us to draw upon the simplicity and scalability of the Transformer architecture, and associated advances in language modeling such as GPT-x and BERT. In particular, we present Decision Transformer, an architecture that casts the problem of RL as conditional sequence modeling. Unlike prior approaches to RL that fit value functions or compute policy gradients, Decision Transformer simply outputs the optimal actions by leveraging a causally masked Transformer. By conditioning an autoregressive model on the desired return (reward), past states, and actions, our Decision Transformer model can generate future actions that achieve the desired return. Despite its simplicity, Decision Transformer matches or exceeds the performance of state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks.},
	urldate = {2021-12-07},
	journal = {arXiv:2106.01345 [cs]},
	author = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Michael and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.01345},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:/home/chinmai/Zotero/storage/MI3NYYZC/2106.html:text/html;arXiv Fulltext PDF:/home/chinmai/Zotero/storage/UBYNAN35/Chen et al. - 2021 - Decision Transformer Reinforcement Learning via S.pdf:application/pdf},
}

@article{elbert_chaos_1994,
	title = {Chaos and physiology: deterministic chaos in excitable cell assemblies},
	volume = {74},
	issn = {0031-9333},
	shorttitle = {Chaos and physiology},
	url = {https://journals.physiology.org/doi/abs/10.1152/physrev.1994.74.1.1},
	doi = {10.1152/physrev.1994.74.1.1},
	abstract = {In this review we examined the emerging science of deterministic chaos (nonlinear systems theory) and its application to selected physiological systems. Although many of the popular images of fractals represent fascination and beauty that by analogy corresponds to nature as we see it, the question remains as to its ultimate meaning for physiological processes. It was our intent to help clarify this somewhat popular, somewhat obscure area of nonlinear dynamics in the context of an ever-changing procedural base. We examined not only the basic concepts of chaos, but also its applications ranging from observations in single cells to the complexity of the EEG. We have not suggested that nonlinear dynamics will answer all of our questions; however, we did attempt to illustrate ways in which this approach may help us to answer new questions and to rearticulate old ones. Chaos is revolutionary in that the overall approach requires us to adopt a different frame of reference which, at times, may move us away from previous concerns and methods of data analysis. In sections I-IV, we summarized the nonlinear dynamics approach and described its application to physiology and neural systems. First, we presented a general overview of the application of nonlinear dynamical techniques to neural systems. We discussed the manner in which even apparently simple deterministic systems can behave in an unpredictable manner. Second, we described the principles of nonlinear dynamical systems including the derived analytical techniques. We now see a variety of procedures for delineating whether frenetic chaotic behavior results from a nonlinear dynamical system with a few degrees of freedom, or whether it is caused by an infinite number of variables, i.e., noise. Third, we approached the applications of nonlinear procedures to the cardiovascular systems and to the neurosciences. In terms of time series, we described initial studies which applied the now "traditional" measures of dimensionality (e.g., based on the algorithm by Grassberger and Procaccia) and information change (e.g., Lyapunov exponents). Examples include our own work and that of Pritchard et al., demonstrating that the dynamics of neural mass activity reflect psychopathological states. Today, however, the trend has expanded to include the use of surrogate data and statistical null hypotheses testing to examine whether a given time series can be considered different from that of white or colored noise (cf. Ref. 262). One of the most important potential applications is that of quantifying changes in nonlinear dynamics to predict future states of the system.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {1},
	urldate = {2021-11-18},
	journal = {Physiological Reviews},
	author = {Elbert, T. and Ray, W. J. and Kowalik, Z. J. and Skinner, J. E. and Graf, K. E. and Birbaumer, N.},
	month = jan,
	year = {1994},
	note = {Publisher: American Physiological Society},
	pages = {1--47},
	file = {Full Text PDF:/home/chinmai/Zotero/storage/MDATSEVJ/Elbert et al. - 1994 - Chaos and physiology deterministic chaos in excit.pdf:application/pdf},
}

@article{yang_representation_2019,
	title = {Representation learning with extreme learning machines and empirical mode decomposition for wind speed forecasting methods},
	volume = {277},
	issn = {0004-3702},
	url = {https://www.sciencedirect.com/science/article/pii/S000437021930181X},
	doi = {10.1016/j.artint.2019.103176},
	abstract = {Time series analysis has become more accurate with the emergence of powerful modelling methods based on machine learning development. Prediction models use historical time series to predict future conditions that occur over periods of time. However, most of these models are shallow models, only containing a small number of non-linear operations and without the ability or the capacity to extract underlying features from complex time series accurately. Moreover, deep learning approaches outperform statistical and computational approaches if a large amount of data and/or hidden layers are involved in the development of a forecasting model, but they are criticized for their relatively slow learning speeds. Therefore, this research proposes a hybrid model, which is hybridized by empirical mode decomposition, stacked auto-encoders, and extreme learning machines, aiming to forecast wind speed accurately and efficiently. The evaluation is undertaken by conducting extensive experiments using real-world data. The results show that the proposed E-S-ELM can accurately and efficiently forecast wind speed, and the effectiveness of the shared-hidden-layer approach for deep networks is also demonstrated.},
	language = {en},
	urldate = {2021-11-18},
	journal = {Artificial Intelligence},
	author = {Yang, Hao-Fan and Chen, Yi-Ping Phoebe},
	month = dec,
	year = {2019},
	keywords = {Deep learning, Empirical mode decomposition, Extreme learning machines, Representation learning},
	pages = {103176},
}

@article{looney_intrinsic_2015,
	title = {Intrinsic multi-scale analysis: a multi-variate empirical mode decomposition framework},
	volume = {471},
	shorttitle = {Intrinsic multi-scale analysis},
	url = {https://royalsocietypublishing.org/doi/10.1098/rspa.2014.0709},
	doi = {10.1098/rspa.2014.0709},
	abstract = {A novel multi-scale approach for quantifying both inter- and intra-component dependence of a complex system is introduced. This is achieved using empirical mode decomposition (EMD), which, unlike conventional scale-estimation methods, obtains a set of scales reflecting the underlying oscillations at the intrinsic scale level. This enables the data-driven operation of several standard data-association measures (intrinsic correlation, intrinsic sample entropy (SE), intrinsic phase synchrony) and, at the same time, preserves the physical meaning of the analysis. The utility of multi-variate extensions of EMD is highlighted, both in terms of robust scale alignment between system components, a pre-requisite for inter-component measures, and in the estimation of feature relevance. We also illuminate that the properties of EMD scales can be used to decouple amplitude and phase information, a necessary step in order to accurately quantify signal dynamics through correlation and SE analysis which are otherwise not possible. Finally, the proposed multi-scale framework is applied to detect directionality, and higher order features such as coupling and regularity, in both synthetic and biological systems.},
	number = {2173},
	urldate = {2021-11-12},
	journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Looney, David and Hemakom, Apit and Mandic, Danilo P.},
	month = jan,
	year = {2015},
	note = {Publisher: Royal Society},
	keywords = {correlation, empirical mode decomposition, multi-variate analysis, phase synchrony, sample entropy},
	pages = {20140709},
	file = {Full Text PDF:/home/chinmai/Zotero/storage/K24BZQHZ/Looney et al. - 2015 - Intrinsic multi-scale analysis a multi-variate em.pdf:application/pdf},
}

@inproceedings{zhu_spatial_2020,
	address = {New York, NY, USA},
	series = {{AIPR} 2020},
	title = {A {Spatial} {Attention}-{Enhanced} {Multi}-{Timescale} {Graph} {Convolutional} {Network} for {Skeleton}-{Based} {Action} {Recognition}},
	isbn = {978-1-4503-7551-1},
	url = {https://doi.org/10.1145/3430199.3430213},
	doi = {10.1145/3430199.3430213},
	abstract = {How to effectively extract discriminative spatial and temporal features is important for skeleton-based action recognition. However, current researches on skeleton-based action recognition mainly focus on the natural connections of the skeleton and original temporal sequences of the skeleton frames, which ignore the inter-related relation of non-adjacent joints and the variant velocities of action instances. To overcome these limitations and therefore enhance the spatial and temporal features extraction for action recognition, we propose a novel Spatial Attention-Enhanced Multi-Timescale Graph Convolutional Network (SA-MTGCN) for skeleton-based action recognition. Specifically, as the relation of non-adjacent but inter-related joints is beneficial for action recognition, we propose an Attention-Enhanced Spatial Graph Convolutional Network (A-SGCN) to use both natural connection and inter-related relation of joints. Furthermore, a Multi-Timescale (MT) structure is proposed to enhance temporal feature extraction by gathering different network layers to model different velocities of action instances. Experimental results on the two widely used NTU and Kinetics datasets demonstrate the effectiveness of our approach.},
	urldate = {2021-11-10},
	booktitle = {Proceedings of the 2020 3rd {International} {Conference} on {Artificial} {Intelligence} and {Pattern} {Recognition}},
	publisher = {Association for Computing Machinery},
	author = {Zhu, Shuqiong and Ding, Xiaolu and Yang, Kai and Chen, Wai},
	month = jun,
	year = {2020},
	keywords = {action recognition, attention, graph convolution, multiscale, skeleton-based},
	pages = {57--62},
	file = {Full Text PDF:/home/chinmai/Zotero/storage/48W4YDUS/Zhu et al. - 2020 - A Spatial Attention-Enhanced Multi-Timescale Graph.pdf:application/pdf},
}

@article{jiang_dynamic_2021,
	title = {Dynamic lane traffic signal control with group attention and multi-timescale reinforcement learning},
	url = {https://ink.library.smu.edu.sg/sis_research/6128},
	doi = {10.24963/ijcai.2021/501},
	journal = {Proceedings of the 30th International Joint Conference on Artificial Intelligence (IJCAI-21), Virtual Conference, 2021 August 19-26},
	author = {JIANG, Qize and LI, Jingze and SUN, Weiwei Sun and ZHENG, Baihua},
	month = aug,
	year = {2021},
	pages = {3642--3648},
	file = {"Dynamic lane traffic signal control with group attention and multi-tim" by Qize JIANG, Jingze LI et al.:/home/chinmai/Zotero/storage/56SIX64Y/6128.html:text/html;Full Text:/home/chinmai/Zotero/storage/AD24FA86/JIANG et al. - 2021 - Dynamic lane traffic signal control with group att.pdf:application/pdf},
}

@article{guhathakurta_computational_2016,
	title = {Computational {Pipeline} for {NIRS}-{EEG} {Joint} {Imaging} of {tDCS}-{Evoked} {Cerebral} {Responses}—{An} {Application} in {Ischemic} {Stroke}},
	volume = {10},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/article/10.3389/fnins.2016.00261},
	doi = {10.3389/fnins.2016.00261},
	abstract = {Transcranial direct current stimulation (tDCS) modulates cortical neural activity and hemodynamics. Electrophysiological methods (electroencephalography-EEG) measure neural activity while optical methods (near-infrared spectroscopy-NIRS) measure hemodynamics coupled through neurovascular coupling (NVC). Assessment of NVC requires development of NIRS-EEG joint-imaging sensor montages that are sensitive to the tDCS affected brain areas. In this methods paper, we present a software pipeline incorporating freely available software tools that can be used to target vascular territories with tDCS and develop a NIRS-EEG probe for joint imaging of tDCS-evoked responses. We apply this software pipeline to target primarily the outer convexity of the brain territory (superficial divisions) of the middle cerebral artery (MCA). We then present a computational method based on Empirical Mode Decomposition of NIRS and EEG time series into a set of intrinsic mode functions (IMFs), and then perform a cross-correlation analysis on those IMFs from NIRS and EEG signals to model NVC at the lesional and contralesional hemispheres of an ischemic stroke patient. For the contralesional hemisphere, a strong positive correlation between IMFs of regional cerebral hemoglobin oxygen saturation and the log-transformed mean-power time-series of IMFs for EEG with a lag of about −15 s was found after a cumulative 550 s stimulation of anodal tDCS. It is postulated that system identification, for example using a continuous-time autoregressive model, of this coupling relation under tDCS perturbation may provide spatiotemporal discriminatory features for the identification of ischemia. Furthermore, portable NIRS-EEG joint imaging can be incorporated into brain computer interfaces to monitor tDCS-facilitated neurointervention as well as cortical reorganization.},
	urldate = {2021-11-10},
	journal = {Frontiers in Neuroscience},
	author = {Guhathakurta, Debarpan and Dutta, Anirban},
	year = {2016},
	pages = {261},
	file = {Full Text PDF:/home/chinmai/Zotero/storage/6EPEBRSC/Guhathakurta and Dutta - 2016 - Computational Pipeline for NIRS-EEG Joint Imaging .pdf:application/pdf},
}

@inproceedings{lebid_multi-timescale_2005,
	title = {Multi-timescale measurements of brain responses in visual cortex during functional stimulation using time-resolved spectroscopy},
	volume = {5826},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/5826/0000/Multi-timescale-measurements-of-brain-responses-in-visual-cortex-during/10.1117/12.604821.full},
	doi = {10.1117/12.604821},
	abstract = {Studies of neurovascular coupling (hemodynamic changes and neuronal activation) in the visual cortex using a time-domain single photon counting system have been undertaken. The system operates in near infrared (NIR) range of spectrum and allows functional brain monitoring to be done non-invasively. The detection system employs a photomultiplier and multi-channel scaler to detect and record emerging photons with sub-microsecond resolution (the effective collection time per curve point is {\textasciitilde} 200 ns). Localisation of the visual evoked potentials in the brain was done using knowledge obtained from electroencephalographic (EEG) studies and previous frequency-domain optical NIR spectroscopic systems. The well-known approach of visual stimulation of the human brain, which consists of an alternating black and white checkerboard pattern used previously for the EEG study of neural responses, is applied here. The checkerboard pattern is synchronized with the multi-channel scaler system and allows the analysis of time variation in back-scattered light, at different stimulation frequencies. Slow hemodynamic changes in the human brain due to Hb-HbO$_{\textrm{2}}$ changes in the blood flow were observed, which is evidence of the system's capability to monitor these changes. Monocular visual tests were undertaken and compared with those done with an EEG system. In some subjects a fast optical response on a time scale commensurate with the neural activity associated with the visual cortex was detected. Future work will concentrate on improved experimental protocols and apparatus to confirm the existence of this important physiological signal.},
	urldate = {2021-11-10},
	booktitle = {Opto-{Ireland} 2005: {Optical} {Sensing} and {Spectroscopy}},
	publisher = {SPIE},
	author = {Lebid, Solomiya and O'Neill, Raymond and Markham, Charles and Ward, Tomás and Coyle, Shirley},
	month = jun,
	year = {2005},
	pages = {606--617},
	file = {Snapshot:/home/chinmai/Zotero/storage/YINYG7UP/12.604821.html:text/html;Full Text PDF:/home/chinmai/Zotero/storage/9KZRWWVD/Lebid et al. - 2005 - Multi-timescale measurements of brain responses in.pdf:application/pdf},
}

@inproceedings{moraitis_spiking_2018,
	title = {Spiking {Neural} {Networks} {Enable} {Two}-{Dimensional} {Neurons} and {Unsupervised} {Multi}-{Timescale} {Learning}},
	doi = {10.1109/IJCNN.2018.8489218},
	abstract = {The capabilities of artificial neural networks (ANNs) are limited by the operations possible at their individual neurons and synapses. For instance, each neuron's activation only represents a single scalar variable. In addition, because neuronal activations may be dominated by a single timescale in the synaptic input, unsupervised learning from data with multiple timescales has not been generally possible. Here we address these by exploiting the continuous-time and asynchronous operation of spiking neural networks (SNNs), i.e. a biologically-inspired type of ANNs. First, we demonstrate how input neurons can be two-dimensional (2D), i.e. each represent two variables. Second, we show unsupervised learning from multiple timescales simultaneously. 2D neurons operate by allocating each variable to a different timescale in their activation, i.e. one variable corresponds to the timing of individual spikes, and another to the spike rate. We show how these can be modulated separately but simultaneously, and we apply this mixed coding technique to encoding images with two modalities, namely, colour and brightness. Unsupervised multi-timescale learning is achieved by synapses with spike-timing-dependent plasticity, combined with varying degrees of short-term plasticity. We demonstrate the successful application of this learning scheme on the unsupervised classification of bimodal pictures encoded by our 2D neurons. Taken together, our results show that SNNs are capable of increasing both the information content of each neuron and the exploitable data in the input. We suggest that through these unique features, SNNs may increase the performance and broaden the applicability of ANNs.},
	booktitle = {2018 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Moraitis, Timoleon and Sebastian, Abu and Eleftheriou, Evangelos},
	month = jul,
	year = {2018},
	note = {ISSN: 2161-4407},
	keywords = {Biological neural networks, Neurons, Timing, Encoding, Image color analysis, Synapses, Two dimensional displays},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:/home/chinmai/Zotero/storage/NMNICJKE/8489218.html:text/html;IEEE Xplore Full Text PDF:/home/chinmai/Zotero/storage/X8V68AAC/Moraitis et al. - 2018 - Spiking Neural Networks Enable Two-Dimensional Neu.pdf:application/pdf},
}

@inproceedings{noauthor_aps_nodate,
	title = {{APS} -{APS} {March} {Meeting} 2021 - {Event} - {Multi}-timescale representation of rat behavior},
	url = {https://meetings.aps.org/Meeting/MAR21/Session/P14.14},
	urldate = {2021-11-10},
	booktitle = {Bulletin of the {American} {Physical} {Society}},
	publisher = {American Physical Society},
	file = {Snapshot:/home/chinmai/Zotero/storage/PBLVIAGT/P14.html:text/html},
}

@article{mahto_multi-timescale_2021,
	title = {Multi-timescale {Representation} {Learning} in {LSTM} {Language} {Models}},
	url = {http://arxiv.org/abs/2009.12727},
	abstract = {Language models must capture statistical dependencies between words at timescales ranging from very short to very long. Earlier work has demonstrated that dependencies in natural language tend to decay with distance between words according to a power law. However, it is unclear how this knowledge can be used for analyzing or designing neural network language models. In this work, we derived a theory for how the memory gating mechanism in long short-term memory (LSTM) language models can capture power law decay. We found that unit timescales within an LSTM, which are determined by the forget gate bias, should follow an Inverse Gamma distribution. Experiments then showed that LSTM language models trained on natural English text learn to approximate this theoretical distribution. Further, we found that explicitly imposing the theoretical distribution upon the model during training yielded better language model perplexity overall, with particular improvements for predicting low-frequency (rare) words. Moreover, the explicit multi-timescale model selectively routes information about different types of words through units with different timescales, potentially improving model interpretability. These results demonstrate the importance of careful, theoretically-motivated analysis of memory and timescale in language models.},
	urldate = {2021-11-10},
	journal = {arXiv:2009.12727 [cs]},
	author = {Mahto, Shivangi and Vo, Vy A. and Turek, Javier S. and Huth, Alexander G.},
	month = mar,
	year = {2021},
	note = {arXiv: 2009.12727},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, 91F20, I.2.6, I.2.7},
	file = {arXiv.org Snapshot:/home/chinmai/Zotero/storage/AG8VFDDG/2009.html:text/html;arXiv Fulltext PDF:/home/chinmai/Zotero/storage/PTST3IT6/Mahto et al. - 2021 - Multi-timescale Representation Learning in LSTM La.pdf:application/pdf},
}

@article{cong_multi-timescale_2017,
	title = {Multi-{Timescale} {Gated} {Neural} {Network} for {Video} {Recognition}},
	volume = {10},
	doi = {10.2174/2213275910666170502144924},
	abstract = {Background: Deep neural network based methods have obtained great progress in a variety of computer vision tasks, as described in various patents. But, so far, it is still a challenge task to model temporal dependencies in the tasks of recognizing object movement from videos. Method:
In this paper, we propose a multi-timescale gated neural network for encoding the temporal dependencies from videos. The developed model stacks multiple gated layers in a recurrent pyramid, which makes it possible to hierarchically model not just pairs but long-term dependencies from video
frames. Additionally, the model combines the Convolutional Neural Networks into its structure that exploits the pictorial nature of the frames and reduces the number of model parameters. Result: We evaluated the proposed model on the datasets of synthetic bouncing-MNIST, standard actions
benchmark of UCF101 and facial expressions benchmark of CK+. The experiment results reveal that on all tasks, the proposed model outperforms the existing approach to build deep stacked gated model and achieves superior performance compared to several recent state-of-the-art techniques. Conclusion:
From the experimental results, we can make the conclusion that our proposed model is able to adapt its structure based on different time scales and can be applied in motion estimation, action recognition and tracking, etc.},
	number = {1},
	journal = {Recent Patents on Computer Science},
	author = {Cong, Liu and Longhua, Ma and Feng, Liu},
	month = feb,
	year = {2017},
	keywords = {Deep learning, optimization, model temporal dependencies, multiplicative interactions, neural networks},
	pages = {96--103},
}

@article{wirsich_multi-timescale_2020,
	title = {Multi-timescale hybrid components of the functional brain connectome: {A} bimodal {EEG}-{fMRI} decomposition},
	volume = {4},
	issn = {2472-1751},
	shorttitle = {Multi-timescale hybrid components of the functional brain connectome},
	url = {https://doi.org/10.1162/netn_a_00135},
	doi = {10.1162/netn_a_00135},
	abstract = {Concurrent electroencephalography (EEG) and functional magnetic resonance imaging (fMRI) bridge brain connectivity across timescales. During concurrent EEG-fMRI resting-state recordings, whole-brain functional connectivity (FC) strength is spatially correlated across modalities. However, cross-modal investigations have commonly remained correlational, and joint analysis of EEG-fMRI connectivity is largely unexplored. Here we investigated if there exist (spatially) independent FC networks linked between modalities. We applied the recently proposed hybrid connectivity independent component analysis (connICA) framework to two concurrent EEG-fMRI resting-state datasets (total 40 subjects). Two robust components were found across both datasets. The first component has a uniformly distributed EEG frequency fingerprint linked mainly to intrinsic connectivity networks (ICNs) in both modalities. Conversely, the second component is sensitive to different EEG frequencies and is primarily linked to intra-ICN connectivity in fMRI but to inter-ICN connectivity in EEG. The first hybrid component suggests that connectivity dynamics within well-known ICNs span timescales, from millisecond range in all canonical frequencies of FCEEG to second range of FCfMRI. Conversely, the second component additionally exposes linked but spatially divergent neuronal processing at the two timescales. This work reveals the existence of joint spatially independent components, suggesting that parts of resting-state connectivity are co-expressed in a linked manner across EEG and fMRI over individuals.Functional connectivity is governed by a whole-brain organization measurable over multiple timescales by functional magnetic resonance imaging (fMRI) and electroencephalography (EEG). The relationship across the whole-brain organization captured at the different timescales of EEG and fMRI is largely unknown. Using concurrent EEG-fMRI, we identified spatially independent components consisting of brain connectivity patterns that co-occur in EEG and fMRI over subjects. We observed a component with similar connectivity organization across EEG and fMRI as well as a component with divergent connectivity. The former component governed all EEG frequencies while the latter was modulated by frequency. These findings show that part of functional connectivity organizes in a common spatial layout over several timescales, while a spatially independent part is modulated by frequency-specific information.},
	number = {3},
	urldate = {2021-11-10},
	journal = {Network Neuroscience},
	author = {Wirsich, Jonathan and Amico, Enrico and Giraud, Anne-Lise and Goñi, Joaquín and Sadaghiani, Sepideh},
	month = jul,
	year = {2020},
	pages = {658--677},
	file = {Snapshot:/home/chinmai/Zotero/storage/LLET8VKM/Multi-timescale-hybrid-components-of-the.html:text/html;Full Text PDF:/home/chinmai/Zotero/storage/T9PMJF3U/Wirsich et al. - 2020 - Multi-timescale hybrid components of the functiona.pdf:application/pdf},
}

@inproceedings{duan_epileptic_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Epileptic {Seizure} {Prediction} {Based} on {Convolutional} {Recurrent} {Neural} {Network} with {Multi}-{Timescale}},
	isbn = {978-3-030-36204-1},
	doi = {10.1007/978-3-030-36204-1_11},
	abstract = {Epilepsy is a common disease that is caused by abnormal discharge of neurons in the brain. The most existing methods for seizure prediction rely on multi kinds of features. To discriminate pre-ictal from inter-ictal patterns of EEG signals, a convolutional recurrent neural network with multi-timescale (MT-CRNN) is proposed for seizure prediction. The network model is built to complement the patient-specific seizure prediction approaches. We firstly calculate the correlation coefficients in eight frequency bands from segmented EEG to highlight the key bands among different people. Then CNN is used to extract features and reduce the data dimension, and the output of CNN acts as input of RNN to learn the implicit relationship of the time series. Furthermore, considering that EEG in different time scales reflect neuron activity in distinct scope, we combine three timescale segments of 1 s, 2 s and 3 s. Experiments are done to validate the performance of the proposed model on the dataset of CHB-MIT, and a promising result of 94.8\% accuracy, 91.7\% sensitivity, and 97.7\% specificity are achieved.},
	language = {en},
	booktitle = {Intelligence {Science} and {Big} {Data} {Engineering}. {Big} {Data} and {Machine} {Learning}},
	publisher = {Springer International Publishing},
	author = {Duan, Lijuan and Hou, Jinze and Qiao, Yuanhua and Miao, Jun},
	editor = {Cui, Zhen and Pan, Jinshan and Zhang, Shanshan and Xiao, Liang and Yang, Jian},
	year = {2019},
	keywords = {Deep learning, EEG, Multi-timescale, Seizure prediction},
	pages = {139--150},
	file = {Springer Full Text PDF:/home/chinmai/Zotero/storage/C4KRGRJM/Duan et al. - 2019 - Epileptic Seizure Prediction Based on Convolutiona.pdf:application/pdf},
}

@article{hamel_multi-timescale_nodate,
	title = {{MULTI}-{TIMESCALE} {PMSCS} {FOR} {MUSIC} {AUDIO} {CLASSIFICATION}},
	language = {en},
	author = {Hamel, Philippe},
	pages = {2},
	file = {Hamel - MULTI-TIMESCALE PMSCS FOR MUSIC AUDIO CLASSIFICATI.pdf:/home/chinmai/Zotero/storage/CXXVEWGV/Hamel - MULTI-TIMESCALE PMSCS FOR MUSIC AUDIO CLASSIFICATI.pdf:application/pdf},
}

@inproceedings{chen_multi-timescale_2019,
	title = {Multi-{Timescale} {Context} {Encoding} for {Scene} {Parsing} {Prediction}},
	doi = {10.1109/ICME.2019.00280},
	abstract = {Predicting the future is a crucial ability for intelligence systems. It is of great importance for many real-world applications, such as autonomous driving, which need scene parsing to understand the environment. Recent research has shown that predicting in semantic level is more effective than segmenting the predicted RGB frames. In order to label pixels in future frames correctly, the rich contextual dependencies should be exploit which existing methods paid less attention to. Therefore, we propose a novel network which catches both the short-term and long-term relations of observed frames for future scene parsing. Specifically, we introduce an attention mechanism to model semantic interdependencies between consecutive frames and a modified convolutional LSTM to model the correlations among all the input frames. Experiments validate that our approach outperforms other state-of-the-art methods on the large-scale Cityscapes dataset.},
	booktitle = {2019 {IEEE} {International} {Conference} on {Multimedia} and {Expo} ({ICME})},
	author = {Chen, Xin and Han, Yahong},
	month = jul,
	year = {2019},
	note = {ISSN: 1945-788X},
	keywords = {Feature extraction, Convolution, ConvLSTM, Correlation, Forecasting, Motion segmentation, Semantic prediction, Semantics, spatial-temporal correlation, Task analysis},
	pages = {1624--1629},
	file = {IEEE Xplore Abstract Record:/home/chinmai/Zotero/storage/KDQVFUBT/8784936.html:text/html;IEEE Xplore Full Text PDF:/home/chinmai/Zotero/storage/M3WK3J5T/Chen and Han - 2019 - Multi-Timescale Context Encoding for Scene Parsing.pdf:application/pdf},
}

@article{jiang_few-shot_2021,
	title = {Few-{Shot} {Learning} in {Spiking} {Neural} {Networks} by {Multi}-{Timescale} {Optimization}},
	volume = {33},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco_a_01423},
	doi = {10.1162/neco_a_01423},
	abstract = {Learning new concepts rapidly from a few examples is an open issue in spike-based machine learning. This few-shot learning imposes substantial challenges to the current learning methodologies of spiking neuron networks (SNNs) due to the lack of task-related priori knowledge. The recent learning-to-learn (L2L) approach allows SNNs to acquire priori knowledge through example-level learning and task-level optimization. However, existing L2L-based frameworks do not target the neural dynamics (i.e., neuronal and synaptic parameter changes) on different timescales. This diversity of temporal dynamics is an important attribute in spike-based learning, which facilitates the networks to rapidly acquire knowledge from very few examples and gradually integrate this knowledge. In this work, we consider the neural dynamics on various timescales and provide a multi-timescale optimization (MTSO) framework for SNNs. This framework introduces an adaptive-gated LSTM to accommodate two different timescales of neural dynamics: short-term learning and long-term evolution. Short-term learning is a fast knowledge acquisition process achieved by a novel surrogate gradient online learning (SGOL) algorithm, where the LSTM guides gradient updating of SNN on a short timescale through an adaptive learning rate and weight decay gating. The long-term evolution aims to slowly integrate acquired knowledge and form a priori, which can be achieved by optimizing the LSTM guidance process to tune SNN parameters on a long timescale. Experimental results demonstrate that the collaborative optimization of multi-timescale neural dynamics can make SNNs achieve promising performance for the few-shot learning tasks.},
	number = {9},
	urldate = {2021-11-10},
	journal = {Neural Computation},
	author = {Jiang, Runhao and Zhang, Jie and Yan, Rui and Tang, Huajin},
	month = aug,
	year = {2021},
	pages = {2439--2472},
	file = {Full Text:/home/chinmai/Zotero/storage/377GVRCD/Jiang et al. - 2021 - Few-Shot Learning in Spiking Neural Networks by Mu.pdf:application/pdf;Snapshot:/home/chinmai/Zotero/storage/PAKEHUEQ/Few-Shot-Learning-in-Spiking-Neural-Networks-by.html:text/html},
}

@article{kobayashi_extracting_2018,
	title = {Extracting the multi-timescale activity patterns of online financial markets},
	volume = {8},
	copyright = {2018 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-018-29537-w},
	doi = {10.1038/s41598-018-29537-w},
	abstract = {Online financial markets can be represented as complex systems where trading dynamics can be captured and characterized at different resolutions and time scales. In this work, we develop a methodology based on non-negative tensor factorization (NTF) aimed at extracting and revealing the multi-timescale trading dynamics governing online financial systems. We demonstrate the advantage of our strategy first using synthetic data, and then on real-world data capturing all interbank transactions (over a million) occurred in an Italian online financial market (e-MID) between 2001 and 2015. Our results demonstrate how NTF can uncover hidden activity patterns that characterize groups of banks exhibiting different trading strategies (normal vs. early vs. flash trading, etc.). We further illustrate how our methodology can reveal “crisis modalities” in trading triggered by endogenous and exogenous system shocks: as an example, we reveal and characterize trading anomalies in the midst of the 2008 financial crisis.},
	language = {en},
	number = {1},
	urldate = {2021-11-10},
	journal = {Scientific Reports},
	author = {Kobayashi, Teruyoshi and Sapienza, Anna and Ferrara, Emilio},
	month = jul,
	year = {2018},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Computer science;Statistical physics, thermodynamics and nonlinear dynamics
Subject\_term\_id: computer-science;statistical-physics-thermodynamics-and-nonlinear-dynamics},
	keywords = {Computer science, Statistical physics, thermodynamics and nonlinear dynamics},
	pages = {11184},
	file = {Snapshot:/home/chinmai/Zotero/storage/IL8QNDMV/s41598-018-29537-w.html:text/html;Full Text PDF:/home/chinmai/Zotero/storage/7LWTFYNR/Kobayashi et al. - 2018 - Extracting the multi-timescale activity patterns o.pdf:application/pdf},
}

@techreport{jain_interpretable_2021,
	title = {Interpretable multi-timescale models for predicting {fMRI} responses to continuous natural speech},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2020.10.02.324392v2},
	abstract = {Natural language contains information at multiple timescales. To understand how the human brain represents this information, one approach is to build encoding models that predict fMRI responses to natural language using representations extracted from neural network language models (LMs). However, these LM-derived representations do not explicitly separate information at different timescales, making it difficult to interpret the encoding models. In this work we construct interpretable multi-timescale representations by forcing individual units in an LSTM LM to integrate information over specific temporal scales. This allows us to explicitly and directly map the timescale of information encoded by each individual fMRI voxel. Further, the standard fMRI encoding procedure does not account for varying temporal properties in the encoding features. We modify the procedure so that it can capture both short- and long-timescale information. This approach outperforms other encoding models, particularly for voxels that represent long-timescale information. It also provides a finer-grained map of timescale information in the human language pathway. This serves as a framework for future work investigating temporal hierarchies across artificial and biological language systems.},
	language = {en},
	urldate = {2021-11-10},
	author = {Jain, Shailee and Mahto, Shivangi and Turek, Javier S. and Vo, Vy A. and LeBel, Amanda and Huth, Alexander G.},
	month = feb,
	year = {2021},
	doi = {10.1101/2020.10.02.324392},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.10.02.324392},
	file = {Snapshot:/home/chinmai/Zotero/storage/VMU3X3PL/2020.10.02.324392v2.html:text/html;Full Text PDF:/home/chinmai/Zotero/storage/V9KXB89K/Jain et al. - 2021 - Interpretable multi-timescale models for predictin.pdf:application/pdf},
}

@inproceedings{mcdaniel_modeling_2020,
	title = {Modeling the {Relationship} {Between} {Cognitive} {State} and {Task} {Performance} in {Passive} {BCIs} using {Cross}-{Dataset} {Learning}},
	doi = {10.1109/SMC42975.2020.9283276},
	abstract = {New research and development efforts are highlighting the ways in which electroencephalogram-based (EEG) brain-computer interface (BCI) technology can be used to improve the quality of life for healthy individuals. One such application incorporates cognitive state monitoring into passive BCI (pBCI) systems. Among the challenges facing this development, a significant barrier to adoption is the time-intensive calibration typically needed to tune the system to account for variations in neural activity patterns. An open research question is understanding the relationship between underlying user state and user performance in real-world situations and environments. However, user states are often derived and defined as a function of observed user performance for a particular analysis. Understanding the relationship between user state and user performance ideally requires the definition of user state be independent of observed user performance. This work represents our initial steps towards this goal by using cross-dataset learning, where we define user state from a dataset recorded in a highly-controlled experiment, building a subject-independent pBCI model to predict user state using deep learning approaches, and applying this pBCI model to analyze user performance in a new, unobserved dataset. We show that user performance varies smoothly across a continuum of pBCI model outputs. Our results highlight a promising approach for dealing with one of the major hurdles in the development of BCI systems for healthy users.},
	booktitle = {2020 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({SMC})},
	author = {McDaniel, Jonathan R. and Gordon, Stephen M. and Lawhern, Vernon J.},
	month = oct,
	year = {2020},
	note = {ISSN: 2577-1655},
	keywords = {Deep Learning, Convolutional Neural Network, Brain modeling, Task analysis, Analytical models, Brain-Computer Interface, Brain-computer interfaces, Electroencephalography, Neural activity, Predictive models, Research and development},
	pages = {4020--4025},
	file = {IEEE Xplore Abstract Record:/home/chinmai/Zotero/storage/433SJVX6/9283276.html:text/html},
}

@article{lawhern_eegnet_2018,
	title = {{EEGNet}: a compact convolutional neural network for {EEG}-based brain–computer interfaces},
	volume = {15},
	issn = {1741-2552},
	shorttitle = {{EEGNet}},
	url = {https://doi.org/10.1088/1741-2552/aace8c},
	doi = {10.1088/1741-2552/aace8c},
	abstract = {Objective. Brain–computer interfaces (BCI) enable direct communication with a computer, using neural activity as the control signal. This neural signal is generally chosen from a variety of well-studied electroencephalogram (EEG) signals. For a given BCI paradigm, feature extractors and classifiers are tailored to the distinct characteristics of its expected EEG control signal, limiting its application to that specific signal. Convolutional neural networks (CNNs), which have been used in computer vision and speech recognition to perform automatic feature extraction and classification, have successfully been applied to EEG-based BCIs; however, they have mainly been applied to single BCI paradigms and thus it remains unclear how these architectures generalize to other paradigms. Here, we ask if we can design a single CNN architecture to accurately classify EEG signals from different BCI paradigms, while simultaneously being as compact as possible. Approach. In this work we introduce EEGNet, a compact convolutional neural network for EEG-based BCIs. We introduce the use of depthwise and separable convolutions to construct an EEG-specific model which encapsulates well-known EEG feature extraction concepts for BCI. We compare EEGNet, both for within-subject and cross-subject classification, to current state-of-the-art approaches across four BCI paradigms: P300 visual-evoked potentials, error-related negativity responses (ERN), movement-related cortical potentials (MRCP), and sensory motor rhythms (SMR). Main results. We show that EEGNet generalizes across paradigms better than, and achieves comparably high performance to, the reference algorithms when only limited training data is available across all tested paradigms. In addition, we demonstrate three different approaches to visualize the contents of a trained EEGNet model to enable interpretation of the learned features. Significance. Our results suggest that EEGNet is robust enough to learn a wide variety of interpretable features over a range of BCI tasks. Our models can be found at: https://github.com/vlawhern/arl-eegmodels.},
	language = {en},
	number = {5},
	urldate = {2021-10-20},
	author = {Lawhern, Vernon J. and Solon, Amelia J. and Waytowich, Nicholas R. and Gordon, Stephen M. and Hung, Chou P. and Lance, Brent J.},
	month = jul,
	year = {2018},
	note = {Publisher: IOP Publishing},
	pages = {056013},
	file = {Submitted Version:/home/chinmai/Zotero/storage/4EX4JHKT/Lawhern et al. - 2018 - EEGNet a compact convolutional neural network for.pdf:application/pdf},
}

@inproceedings{goel_thinking_2017,
	title = {Thinking fast and slow: {Optimization} decomposition across timescales},
	shorttitle = {Thinking fast and slow},
	doi = {10.1109/CDC.2017.8263834},
	abstract = {Many real-world control systems, such as the smart grid and human sensorimotor control systems, have decentralized components that react quickly using local information and centralized components that react slowly using a more global view. This paper seeks to provide a theoretical framework for how to design controllers that are decomposed across timescales in this way. The framework is analogous to how the network utility maximization framework uses optimization decomposition to distribute a global control problem across independent controllers, each of which solves a local problem; except our goal is to decompose a global problem temporally, extracting a timescale separation. Our results highlight that decomposition of a multi-timescale controller into a fast timescale, reactive controller and a slow timescale, predictive controller can be near-optimal in a strong sense. In particular, we exhibit such a design, named Multi-timescale Reflexive Predictive Control (MRPC), which maintains a pertimestep cost within a constant factor of the offline optimal in an adversarial setting.},
	booktitle = {2017 {IEEE} 56th {Annual} {Conference} on {Decision} and {Control} ({CDC})},
	author = {Goel, Gautam and Chen, Niangjun and Wierman, Adam},
	month = dec,
	year = {2017},
	keywords = {Robots, Algorithm design and analysis, Economics, Optimal control, Optimization, Prediction algorithms},
	pages = {1291--1298},
	file = {IEEE Xplore Abstract Record:/home/chinmai/Zotero/storage/H7Q7EQYN/8263834.html:text/html;Accepted Version:/home/chinmai/Zotero/storage/MLF3VC7P/Goel et al. - 2017 - Thinking fast and slow Optimization decomposition.pdf:application/pdf},
}

@inproceedings{adamson_busy_2017,
	address = {Barcelona Spain},
	title = {Busy beeway: a game for testing human-automation collaboration for navigation},
	isbn = {978-1-4503-5541-4},
	shorttitle = {Busy beeway},
	url = {https://dl.acm.org/doi/10.1145/3136457.3136471},
	doi = {10.1145/3136457.3136471},
	abstract = {Motion planning in stochastic dynamic environments is a di cult problem with many applications towards self-driving vehicles, UAVs, and video games. Human-automation collaboration can enhance navigation safety and e ciency in situations where pure automation is not satisfactory, but it o en relies on interface design to prevent over-reliance or under-reliance of the automation. Commodity input devices for collaborative interfaces are currently emerging as an alternative to specialized hardware and expensive simulators. is study presents Busy Beeway, a mobile game platform to study human-automation collaboration in dynamic environments. Users share control with automation as they evade stochastically moving obstacles in levels of increasing di culty. In this paper, data collection from game play is combined with survey feedback to provide insight into Busy Beeway’s potential to aid human-automation collaboration for navigation tasks.},
	language = {en},
	urldate = {2022-03-02},
	booktitle = {Proceedings of the {Tenth} {International} {Conference} on {Motion} in {Games}},
	publisher = {ACM},
	author = {Adamson, Torin and Oishi, Meeko and Chiang, Hao-Tien (Lewis) and Tapia, Lydia},
	month = nov,
	year = {2017},
	pages = {1--6},
	file = {Adamson et al. - 2017 - Busy beeway a game for testing human-automation c.pdf:/home/chinmai/Zotero/storage/GPNJ5GIT/Adamson et al. - 2017 - Busy beeway a game for testing human-automation c.pdf:application/pdf},
}

@article{wu_driver_2017,
	title = {Driver {Drowsiness} {Estimation} {From} {EEG} {Signals} {Using} {Online} {Weighted} {Adaptation} {Regularization} for {Regression} ({OwARR})},
	volume = {25},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2016.2633379},
	abstract = {One big challenge that hinders the transition of brain-computer interfaces (BCIs) from laboratory settings to real-life applications is the availability of high-performance and robust learning algorithms that can effectively handle individual differences, i.e., algorithms that can be applied to a new subject with zero or very little subject-specific calibration data. Transfer learning and domain adaptation have been extensively used for this purpose. However, most previous works focused on classification problems. This paper considers an important regression problem in BCI, namely, online driver drowsiness estimation from EEG signals. By integrating fuzzy sets with domain adaptation, we propose a novel online weighted adaptation regularization for regression (OwARR) algorithm to reduce the amount of subject-specific calibration data, and also a source domain selection (SDS) approach to save about half of the computational cost of OwARR. Using a simulated driving dataset with 15 subjects, we show that OwARR and OwARR-SDS can achieve significantly smaller estimation errors than several other approaches. We also provide comprehensive analyses on the robustness of OwARR and OwARR-SDS.},
	number = {6},
	journal = {IEEE Transactions on Fuzzy Systems},
	author = {Wu, Dongrui and Lawhern, Vernon J. and Gordon, Stephen and Lance, Brent J. and Lin, Chin-Teng},
	month = dec,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Fuzzy Systems},
	keywords = {Brain modeling, Probability distribution, EEG, Electroencephalography, Brain–computer interface, Calibration, domain adaptation (DA), ensemble learning, Estimation, Frequency selective surfaces, fuzzy sets (FSs), Robustness, transfer learning (TL)},
	pages = {1522--1535},
	file = {Full Text:/home/chinmai/Zotero/storage/MCPM4SPT/Wu et al. - 2017 - Driver Drowsiness Estimation From EEG Signals Usin.pdf:application/pdf;IEEE Xplore Abstract Record:/home/chinmai/Zotero/storage/88ZGK84R/7762132.html:text/html},
}

@article{lawhern_detection_2012,
	title = {Detection and classification of subject-generated artifacts in {EEG} signals using autoregressive models},
	volume = {208},
	issn = {0165-0270},
	url = {https://www.sciencedirect.com/science/article/pii/S0165027012001860},
	doi = {10.1016/j.jneumeth.2012.05.017},
	abstract = {We examine the problem of accurate detection and classification of artifacts in continuous EEG recordings. Manual identification of artifacts, by means of an expert or panel of experts, can be tedious, time-consuming and infeasible for large datasets. We use autoregressive (AR) models for feature extraction and characterization of EEG signals containing several kinds of subject-generated artifacts. AR model parameters are scale-invariant features that can be used to develop models of artifacts across a population. We use a support vector machine (SVM) classifier to discriminate among artifact conditions using the AR model parameters as features. Results indicate reliable classification among several different artifact conditions across subjects (approximately 94\%). These results suggest that AR modeling can be a useful tool for discriminating among artifact signals both within and across individuals.},
	language = {en},
	number = {2},
	urldate = {2022-03-02},
	journal = {Journal of Neuroscience Methods},
	author = {Lawhern, Vernon and Hairston, W. David and McDowell, Kaleb and Westerfield, Marissa and Robbins, Kay},
	month = jul,
	year = {2012},
	keywords = {Support vector machines, Electroencephalography, Artifacts, Autoregressive model},
	pages = {181--189},
	file = {ScienceDirect Snapshot:/home/chinmai/Zotero/storage/594GQYST/S0165027012001860.html:text/html},
}

@article{lawhern_eegnet_2018-1,
	title = {{EEGNet}: a compact convolutional neural network for {EEG}-based brain–computer interfaces},
	volume = {15},
	issn = {1741-2560, 1741-2552},
	shorttitle = {{EEGNet}},
	url = {https://iopscience.iop.org/article/10.1088/1741-2552/aace8c},
	doi = {10.1088/1741-2552/aace8c},
	abstract = {Objective. Brain–computer interfaces (BCI) enable direct communication with a computer, using neural activity as the control signal. This neural signal is generally chosen from a variety of well-studied electroencephalogram (EEG) signals. For a given BCI paradigm, feature extractors and classifiers are tailored to the distinct characteristics of its expected EEG control signal, limiting its application to that specific signal. Convolutional neural networks (CNNs), which have been used in computer vision and speech recognition to perform automatic feature extraction and classification, have successfully been applied to EEG-based BCIs; however, they have mainly been applied to single BCI paradigms and thus it remains unclear how these architectures generalize to other paradigms. Here, we ask if we can design a single CNN architecture to accurately classify EEG signals from different BCI paradigms, while simultaneously being as compact as possible. Approach. In this work we introduce EEGNet, a compact convolutional neural network for EEG-based BCIs. We introduce the use of depthwise and separable convolutions to construct an EEG-specific model which encapsulates well-known EEG feature extraction concepts for BCI. We compare EEGNet, both for within-subject and cross-subject classification, to current state-of-the-art approaches across four BCI paradigms: P300 visual-evoked potentials, error-related negativity responses (ERN), movement-related cortical potentials (MRCP), and sensory motor rhythms (SMR).},
	language = {en},
	number = {5},
	urldate = {2022-03-02},
	journal = {Journal of Neural Engineering},
	author = {Lawhern, Vernon J and Solon, Amelia J and Waytowich, Nicholas R and Gordon, Stephen M and Hung, Chou P and Lance, Brent J},
	month = oct,
	year = {2018},
	pages = {056013},
	file = {Lawhern et al. - 2018 - EEGNet a compact convolutional neural network for.pdf:/home/chinmai/Zotero/storage/PE4LLDPB/Lawhern et al. - 2018 - EEGNet a compact convolutional neural network for.pdf:application/pdf},
}

@inproceedings{chollet_xception_2017,
	title = {Xception: {Deep} {Learning} {With} {Depthwise} {Separable} {Convolutions}},
	shorttitle = {Xception},
	url = {https://openaccess.thecvf.com/content_cvpr_2017/html/Chollet_Xception_Deep_Learning_CVPR_2017_paper.html},
	urldate = {2022-03-03},
	author = {Chollet, Francois},
	year = {2017},
	pages = {1251--1258},
	file = {Full Text PDF:/home/chinmai/Zotero/storage/3WV2DXUL/Chollet - 2017 - Xception Deep Learning With Depthwise Separable C.pdf:application/pdf;Snapshot:/home/chinmai/Zotero/storage/84TEQ6JJ/Chollet_Xception_Deep_Learning_CVPR_2017_paper.html:text/html},
}

@inproceedings{sreeja_motor_2017,
	title = {Motor {Imagery} {EEG} {Signal} {Processing} and {Classification} {Using} {Machine} {Learning} {Approach}},
	doi = {10.1109/ICTCS.2017.15},
	abstract = {Motor imagery (MI) signals recorded via electroencephalography (EEG) is the most convenient basis for designing brain-computer interfaces (BCIs). As MI based BCI provides high degree of freedom, it helps motor disabled people to communicate with the device by performing sequence of MI tasks. But inter-subject variability, extracting user-specific features and increasing accuracy of the classifier is still a challenging task in MI based BCIs. In this work, we propose an approach to overcome the above mentioned issues. The proposed approach follows the pipeline such as channel selection, band-pass filter based CSP (common spatial pattern), feature extraction, feature selection using two different techniques and modeling using Gaussian Naïve Bayes (GNB) classifier. Since the optimal features are selected by feature selection techniques, it helps to overcome inter-subject variability and improves performance of GNB classifier. To the best of our knowledge, the proposed methodology has not been used for MI-based BCI applications. The proposed approach is validated using BCI competition III dataset IVa. The result of our proposed approach is compared with two conventional classifiers such as linear discriminant analysis (LDA) and support vector machine (SVM). The results prove that the proposed method provides an improved accuracy than LDA and SVM classifiers. The proposed method can be further developed to design a reliable and real-time MI-based BCI application.},
	booktitle = {2017 {International} {Conference} on {New} {Trends} in {Computing} {Sciences} ({ICTCS})},
	author = {Sreeja, S.R. and Rabha, Joytirmoy and Nagarjuna, K.Y. and Samanta, Debasis and Mitra, Pabitra and Sarma, Monalisa},
	month = oct,
	year = {2017},
	keywords = {Feature extraction, machine learning, feature extraction, EEG, Electroencephalography, Band-pass filters, BCI, Electrodes, feature selection, Frequency-domain analysis, Motor Imagery, Time-domain analysis},
	pages = {61--66},
	file = {IEEE Xplore Abstract Record:/home/chinmai/Zotero/storage/ACTRDASJ/8250265.html:text/html},
}

@article{dempster_rocket_2020,
	title = {{ROCKET}: exceptionally fast and accurate time series classification using random convolutional kernels},
	volume = {34},
	issn = {1573-756X},
	shorttitle = {{ROCKET}},
	url = {https://doi.org/10.1007/s10618-020-00701-z},
	doi = {10.1007/s10618-020-00701-z},
	abstract = {Most methods for time series classification that attain state-of-the-art accuracy have high computational complexity, requiring significant training time even for smaller datasets, and are intractable for larger datasets. Additionally, many existing methods focus on a single type of feature such as shape or frequency. Building on the recent success of convolutional neural networks for time series classification, we show that simple linear classifiers using random convolutional kernels achieve state-of-the-art accuracy with a fraction of the computational expense of existing methods. Using this method, it is possible to train and test a classifier on all 85 ‘bake off’ datasets in the UCR archive in \$\${\textless}{\textbackslash},2{\textbackslash},{\textbackslash}hbox \{h\}\$\$, and it is possible to train a classifier on a large dataset of more than one million time series in approximately 1 h.},
	language = {en},
	number = {5},
	urldate = {2022-03-11},
	journal = {Data Mining and Knowledge Discovery},
	author = {Dempster, Angus and Petitjean, François and Webb, Geoffrey I.},
	month = sep,
	year = {2020},
	pages = {1454--1495},
	file = {Springer Full Text PDF:/home/chinmai/Zotero/storage/6NX2D6W5/Dempster et al. - 2020 - ROCKET exceptionally fast and accurate time serie.pdf:application/pdf},
}

@inproceedings{ma_modeling_2018,
	address = {London United Kingdom},
	title = {Modeling {Task} {Relationships} in {Multi}-task {Learning} with {Multi}-gate {Mixture}-of-{Experts}},
	isbn = {978-1-4503-5552-0},
	url = {https://dl.acm.org/doi/10.1145/3219819.3220007},
	doi = {10.1145/3219819.3220007},
	abstract = {Neural-based multi-task learning has been successfully used in many real-world large-scale applications such as recommendation systems. For example, in movie recommendations, beyond providing users movies which they tend to purchase and watch, the system might also optimize for users liking the movies afterwards. With multi-task learning, we aim to build a single model that learns these multiple goals and tasks simultaneously. However, the prediction quality of commonly used multi-task models is often sensitive to the relationships between tasks. It is therefore important to study the modeling tradeo s between task-speci c objectives and inter-task relationships.},
	language = {en},
	urldate = {2022-05-04},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Ma, Jiaqi and Zhao, Zhe and Yi, Xinyang and Chen, Jilin and Hong, Lichan and Chi, Ed H.},
	month = jul,
	year = {2018},
	pages = {1930--1939},
	file = {Ma et al. - 2018 - Modeling Task Relationships in Multi-task Learning.pdf:/home/chinmai/Zotero/storage/F2VTW6MH/Ma et al. - 2018 - Modeling Task Relationships in Multi-task Learning.pdf:application/pdf},
}

@article{cui_multi-scale_2016,
	title = {Multi-{Scale} {Convolutional} {Neural} {Networks} for {Time} {Series} {Classification}},
	url = {http://arxiv.org/abs/1603.06995},
	abstract = {Time series classification (TSC), the problem of predicting class labels of time series, has been around for decades within the community of data mining and machine learning, and found many important applications such as biomedical engineering and clinical prediction. However, it still remains challenging and falls short of classification accuracy and efficiency. Traditional approaches typically involve extracting discriminative features from the original time series using dynamic time warping (DTW) or shapelet transformation, based on which an off-the-shelf classifier can be applied. These methods are ad-hoc and separate the feature extraction part with the classification part, which limits their accuracy performance. Plus, most existing methods fail to take into account the fact that time series often have features at different time scales. To address these problems, we propose a novel end-to-end neural network model, Multi-Scale Convolutional Neural Networks (MCNN), which incorporates feature extraction and classification in a single framework. Leveraging a novel multi-branch layer and learnable convolutional layers, MCNN automatically extracts features at different scales and frequencies, leading to superior feature representation. MCNN is also computationally efficient, as it naturally leverages GPU computing. We conduct comprehensive empirical evaluation with various existing methods on a large number of benchmark datasets, and show that MCNN advances the state-of-the-art by achieving superior accuracy performance than other leading methods.},
	urldate = {2022-05-04},
	journal = {arXiv:1603.06995 [cs]},
	author = {Cui, Zhicheng and Chen, Wenlin and Chen, Yixin},
	month = may,
	year = {2016},
	note = {arXiv: 1603.06995},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv.org Snapshot:/home/chinmai/Zotero/storage/34S2S4QK/1603.html:text/html;arXiv Fulltext PDF:/home/chinmai/Zotero/storage/DY2N5W94/Cui et al. - 2016 - Multi-Scale Convolutional Neural Networks for Time.pdf:application/pdf},
}

@misc{brownlee_making_2017,
	title = {Making {Predictions} with {Sequences}},
	url = {https://machinelearningmastery.com/sequence-prediction/},
	abstract = {Sequence prediction is different from other types of supervised learning problems. The sequence imposes an order on the observations that must be preserved when training models and making predictions. Generally, prediction problems that involve sequence data are referred to as sequence prediction problems, although there are a suite of problems that differ based on the […]},
	language = {en-US},
	urldate = {2022-05-13},
	journal = {Machine Learning Mastery},
	author = {Brownlee, Jason},
	month = sep,
	year = {2017},
	file = {Snapshot:/home/chinmai/Zotero/storage/IU5R7QFU/sequence-prediction.html:text/html},
}

@misc{noauthor_spmf_nodate,
	title = {{SPMF}: {A} {Java} {Open}-{Source} {Data} {Mining} {Library}},
	url = {https://www.philippe-fournier-viger.com/spmf/index.php},
	urldate = {2022-05-13},
	file = {SPMF\: A Java Open-Source Data Mining Library:/home/chinmai/Zotero/storage/4FVFLTSF/index.html:text/html},
}
